# -*- coding: utf-8 -*-
"""Caption_it

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vTHax4AFnDzR8pquwrEMqeZ5JM7LNpkO
"""
import keras.backend.tensorflow_backend as tb
tb._SYMBOLIC_SCOPE.value = True
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import keras
import json
import pickle
from keras.applications.vgg16 import VGG16
from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from keras.preprocessing import image
from keras.models import Model
from tensorflow.keras.models import load_model
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical
from keras.layers import Input, Dense, Dropout, Embedding, LSTM
from keras.layers.merge import add

model = load_model("Weights/Caption_model.h5")
model._make_predict_function()

model_temp = ResNet50(weights="imagenet", input_shape=(224,224,3))

model_resnet = Model(model_temp.input, model_temp.layers[-2].output)
model_resnet._make_predict_function()

def preprocess_image(img):
    img = image.load_img(img, target_size=(224,224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    return img

def encode_image(img):
    img = preprocess_image(img)
    feature_vector = model_resnet.predict(img)
    feature_vector = feature_vector.reshape(1, feature_vector.shape[1])
    return feature_vector

with open("Weights/word_to_idx.pkl", 'rb') as w2i:
    word_to_idx = pickle.load(w2i)
    
with open("Weights/idx_to_word.pkl", 'rb') as i2w:
    idx_to_word = pickle.load(i2w)




idx_to_word[5119] = 'startseq'
word_to_idx['startseq'] = 5119

idx_to_word[5120] = 'endseq'
word_to_idx['endseq'] = 5120

vocab_size = len(word_to_idx) + 1
#print("Vocab Size",vocab_size)

def predict_caption(photo):
    in_text = "startseq"
    max_len = 74
    for i in range(max_len):
        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]
        sequence = pad_sequences([sequence], maxlen=max_len, padding='post')

        ypred =  model.predict([photo,sequence])
        ypred = ypred.argmax()
        word = idx_to_word[ypred]
        in_text+= ' ' +word
        
        if word =='endseq':
            break
        
        
    final_caption =  in_text.split()
    final_caption = final_caption[1:-1]
    final_caption = ' '.join(final_caption)
    
    return final_caption

def caption_this_image(image):

    enc = encode_image(image)
    caption = predict_caption(enc)
    #print(caption)
    return caption

#caption_this_image('img_test.jpg')



